#!/usr/bin/env bash


python ./main/run/full.py -- \
    train_coach:force_retrain:"false" \
    test_predictor:force_recompute:"false" \
    env_name:"LunarLanderContinuous-v2" \
    load:agent_path:"./subrepos/rl-trained-agents/sac/LunarLanderContinuous-v2_1/LunarLanderContinuous-v2.zip" \
    experiment_name:"baseline_1"

# 
# consistent_value_loss
# 
python ./main/run/full.py -- \
    train_coach:force_retrain:"false" \
    test_predictor:force_recompute:"false" \
    env_name:"LunarLanderContinuous-v2" \
    load:agent_path:"./subrepos/rl-trained-agents/sac/LunarLanderContinuous-v2_1/LunarLanderContinuous-v2.zip" \
    experiment_name:"consistent_value_loss_1" \
    train_coach:loss_function:"consistent_value_loss"

# 
# consistent_coach_loss
# 
python ./main/run/full.py -- \
    train_coach:force_retrain:"false" \
    test_predictor:force_recompute:"false" \
    env_name:"LunarLanderContinuous-v2" \
    load:agent_path:"./subrepos/rl-trained-agents/sac/LunarLanderContinuous-v2_1/LunarLanderContinuous-v2.zip" \
    experiment_name:"consistent_coach_loss_1" \
    train_coach:loss_function:"consistent_coach_loss" \
    train_coach:consistent_coach_loss:scale_future_state_loss:"1"

# 
# half_consistent_coach_loss
# 
python ./main/run/full.py -- \
    train_coach:force_retrain:"false" \
    test_predictor:force_recompute:"false" \
    env_name:"LunarLanderContinuous-v2" \
    load:agent_path:"./subrepos/rl-trained-agents/sac/LunarLanderContinuous-v2_1/LunarLanderContinuous-v2.zip" \
    experiment_name:"half_consistent_coach_loss_1" \
    train_coach:loss_function:"half_consistent_coach_loss" \
    train_coach:consistent_coach_loss:scale_future_state_loss:"1" \
    train_coach:number_of_epochs:500

# python ./main/run/full.py -- experiment_name:state_loss_1_with_sac11 train_agent:model_name:default_sac_11

# python ./main/run/full.py -- experiment_name:coach_loss_1_with_sac4_epochs100  train_coach:train_coach:loss_function:consistent_coach_loss 

# python ./main/run/full.py -- experiment_name:coach_loss_1_with_sac4_epochs100  train_coach:train_coach:loss_function:consistent_coach_loss 

python ./main/run/full.py -- \
    env_name:"LunarLanderContinuous-v2" \
    train_coach:loss_function:"consistent_coach_loss" \
    load:agent_path:"./subrepos/rl-trained-agents/sac/LunarLanderContinuous-v2_1/LunarLanderContinuous-v2.zip" \
    experiment_name:"find_best_coefficient_0.01" \
    train_coach:consistent_coach_loss:scale_future_state_loss:"11000000" &

python ./main/run/full.py -- \
    env_name:"LunarLanderContinuous-v2" \
    train_coach:loss_function:"consistent_coach_loss" \
    load:agent_path:"./subrepos/rl-trained-agents/sac/LunarLanderContinuous-v2_1/LunarLanderContinuous-v2.zip" \
    experiment_name:"find_best_coefficient_0.1" \
    train_coach:consistent_coach_loss:scale_future_state_loss:"11000000" &

python ./main/run/full.py -- \
    env_name:"LunarLanderContinuous-v2" \
    train_coach:loss_function:"consistent_coach_loss"  \
    load:agent_path:"./subrepos/rl-trained-agents/sac/LunarLanderContinuous-v2_1/LunarLanderContinuous-v2.zip" \
    experiment_name:"find_best_coefficient_0.3" \
    train_coach:consistent_coach_loss:scale_future_state_loss:"31000000" &

python ./main/run/full.py -- \
    env_name:"LunarLanderContinuous-v2" \
    train_coach:loss_function:"consistent_coach_loss"  \
    load:agent_path:"./subrepos/rl-trained-agents/sac/LunarLanderContinuous-v2_1/LunarLanderContinuous-v2.zip" \
    experiment_name:"find_best_coefficient_0.5" \
    train_coach:consistent_coach_loss:scale_future_state_loss:"51000000" &

python ./main/run/full.py -- \
    env_name:"LunarLanderContinuous-v2" \
    train_coach:loss_function:"consistent_coach_loss"  \
    load:agent_path:"./subrepos/rl-trained-agents/sac/LunarLanderContinuous-v2_1/LunarLanderContinuous-v2.zip" \
    experiment_name:"find_best_coefficient_0.7" \
    train_coach:consistent_coach_loss:scale_future_state_loss:"71000000" &

python ./main/run/full.py -- \
    env_name:"LunarLanderContinuous-v2" \
    train_coach:loss_function:"consistent_coach_loss"  \
    load:agent_path:"./subrepos/rl-trained-agents/sac/LunarLanderContinuous-v2_1/LunarLanderContinuous-v2.zip" \
    experiment_name:"find_best_coefficient_0.9" \
    train_coach:consistent_coach_loss:scale_future_state_loss:"91000000" &

python ./main/run/full.py -- \
    env_name:"LunarLanderContinuous-v2" \
    train_coach:loss_function:"consistent_coach_loss"  \
    load:agent_path:"./subrepos/rl-trained-agents/sac/LunarLanderContinuous-v2_1/LunarLanderContinuous-v2.zip" \
    experiment_name:"find_best_coefficient_1.1" \
    train_coach:consistent_coach_loss:scale_future_state_loss:"11000000" &

python ./main/run/full.py -- \
    env_name:"LunarLanderContinuous-v2" \
    train_coach:loss_function:"consistent_coach_loss"  \
    load:agent_path:"./subrepos/rl-trained-agents/sac/LunarLanderContinuous-v2_1/LunarLanderContinuous-v2.zip" \
    experiment_name:"find_best_coefficient_1.3" \
    train_coach:consistent_coach_loss:scale_future_state_loss:"31000000" &

python ./main/run/full.py -- \
    env_name:"LunarLanderContinuous-v2" \
    train_coach:loss_function:"consistent_coach_loss"  \
    load:agent_path:"./subrepos/rl-trained-agents/sac/LunarLanderContinuous-v2_1/LunarLanderContinuous-v2.zip" \
    experiment_name:"find_best_coefficient_1.5" \
    train_coach:consistent_coach_loss:scale_future_state_loss:"51000000" &

python ./main/run/full.py -- \
    env_name:"LunarLanderContinuous-v2" \
    train_coach:loss_function:"consistent_coach_loss"  \
    load:agent_path:"./subrepos/rl-trained-agents/sac/LunarLanderContinuous-v2_1/LunarLanderContinuous-v2.zip" \
    experiment_name:"find_best_coefficient_1.7" \
    train_coach:consistent_coach_loss:scale_future_state_loss:"71000000" &

python ./main/run/full.py -- \
    env_name:"LunarLanderContinuous-v2" \
    train_coach:loss_function:"consistent_coach_loss"  \
    load:agent_path:"./subrepos/rl-trained-agents/sac/LunarLanderContinuous-v2_1/LunarLanderContinuous-v2.zip" \
    experiment_name:"find_best_coefficient_1.9" \
    train_coach:consistent_coach_loss:scale_future_state_loss:"91000000" &

# HopperBulletEnv-v0
# AntBulletEnv-v0
# BipedalWalker-v3
# HalfCheetahBulletEnv-v0


python ./main/run/full.py -- \
    experiment_name:"consistent_value_loss_1" \
    env_name:"LunarLanderContinuous-v2" \
    load:agent_path:"./subrepos/rl-trained-agents/sac/LunarLanderContinuous-v2_1/LunarLanderContinuous-v2.zip" \
    train_coach:force_retrain:false train_coach:loss_function:"consistent_value_loss" \
    train_coach:number_of_epochs:50 \
    test_predictor:force_recompute:false \
    train_coach:consistent_coach_loss:scale_future_state_loss:"10000000"

python ./main/run/full.py -- \
    env_name:"LunarLanderContinuous-v2" \
    train_coach:force_retrain:false train_coach:loss_function:"consistent_coach_loss" \
    load:agent_path:"./subrepos/rl-trained-agents/sac/LunarLanderContinuous-v2_1/LunarLanderContinuous-v2.zip" \
    experiment_name:"find_best_coefficient_0" \
    test_predictor:force_recompute:false \
    train_coach:consistent_coach_loss:scale_future_state_loss:"0"


python ./main/run/full.py -- \
    env_name:"LunarLanderContinuous-v2" \
    train_coach:force_retrain:false train_coach:loss_function:"consistent_coach_loss" \
    load:agent_path:"./subrepos/rl-trained-agents/sac/LunarLanderContinuous-v2_1/LunarLanderContinuous-v2.zip" \
    experiment_name:"find_best_coefficient_1_multiply" \
    test_predictor:force_recompute:false \
    train_coach:consistent_coach_loss:scale_future_state_loss:"1"

python ./main/run/full.py -- \
    env_name:"LunarLanderContinuous-v2" \
    train_coach:force_retrain:false train_coach:loss_function:"value_prediction_loss" \
    load:agent_path:"./subrepos/rl-trained-agents/sac/LunarLanderContinuous-v2_1/LunarLanderContinuous-v2.zip" \
    experiment_name:"value_predict" \
    test_predictor:force_recompute:false 

python ./main/run/full.py -- \
    env_name:"LunarLanderContinuous-v2" \
    train_coach:force_retrain:false train_coach:loss_function:"value_prediction_loss" \
    load:agent_path:"./subrepos/rl-trained-agents/sac/LunarLanderContinuous-v2_1/LunarLanderContinuous-v2.zip" \
    experiment_name:"value_predict" \
    test_predictor:force_recompute:false 



python ./main/run/full.py -- \
    train_coach:force_retrain:true \
    test_predictor:force_recompute:false \
    train_coach:loss_function:"consistent_coach_loss" \
    experiment_name:"find_best_coefficient_1_all_three" \
    train_coach:consistent_coach_loss:scale_future_state_loss:"1" \
    env_name:"LunarLanderContinuous-v2" \
    load:agent_path:"./subrepos/rl-trained-agents/sac/LunarLanderContinuous-v2_1/LunarLanderContinuous-v2.zip" 