#!/usr/bin/env bash


python ./main/run/full.py -- \
    env_name:"LunarLanderContinuous-v2" \
    load:agent_path:"./subrepos/rl-trained-agents/sac/LunarLanderContinuous-v2_1/LunarLanderContinuous-v2.zip" \
    experiment_name:"best_state_loss" 

python ./main/run/test_visuals.py -- \
    env_name:"LunarLanderContinuous-v2" \
    load:agent_path:"./subrepos/rl-trained-agents/sac/LunarLanderContinuous-v2_1/LunarLanderContinuous-v2.zip" \
    experiment_name:"best_state_loss" 

# python ./main/run/full.py -- experiment_name:state_loss_1_with_sac11 train_agent:model_name:default_sac_11

# python ./main/run/full.py -- experiment_name:coach_loss_1_with_sac4_epochs100  train_coach:train_coach:loss_function:consistent_coach_loss 

# python ./main/run/full.py -- experiment_name:coach_loss_1_with_sac4_epochs100  train_coach:train_coach:loss_function:consistent_coach_loss 

python ./main/run/full.py -- \
    env_name:"LunarLanderContinuous-v2" \
    train_coach:loss_function:"consistent_coach_loss" \
    load:agent_path:"./subrepos/rl-trained-agents/sac/LunarLanderContinuous-v2_1/LunarLanderContinuous-v2.zip" \
    experiment_name:"find_best_coefficient_0.01" \
    train_coach:consistent_coach_loss:scale_future_state_loss:"11000000" &

python ./main/run/full.py -- \
    env_name:"LunarLanderContinuous-v2" \
    train_coach:loss_function:"consistent_coach_loss" \
    load:agent_path:"./subrepos/rl-trained-agents/sac/LunarLanderContinuous-v2_1/LunarLanderContinuous-v2.zip" \
    experiment_name:"find_best_coefficient_0.1" \
    train_coach:consistent_coach_loss:scale_future_state_loss:"11000000" &

python ./main/run/full.py -- \
    env_name:"LunarLanderContinuous-v2" \
    train_coach:loss_function:"consistent_coach_loss"  \
    load:agent_path:"./subrepos/rl-trained-agents/sac/LunarLanderContinuous-v2_1/LunarLanderContinuous-v2.zip" \
    experiment_name:"find_best_coefficient_0.3" \
    train_coach:consistent_coach_loss:scale_future_state_loss:"31000000" &

python ./main/run/full.py -- \
    env_name:"LunarLanderContinuous-v2" \
    train_coach:loss_function:"consistent_coach_loss"  \
    load:agent_path:"./subrepos/rl-trained-agents/sac/LunarLanderContinuous-v2_1/LunarLanderContinuous-v2.zip" \
    experiment_name:"find_best_coefficient_0.5" \
    train_coach:consistent_coach_loss:scale_future_state_loss:"51000000" &

python ./main/run/full.py -- \
    env_name:"LunarLanderContinuous-v2" \
    train_coach:loss_function:"consistent_coach_loss"  \
    load:agent_path:"./subrepos/rl-trained-agents/sac/LunarLanderContinuous-v2_1/LunarLanderContinuous-v2.zip" \
    experiment_name:"find_best_coefficient_0.7" \
    train_coach:consistent_coach_loss:scale_future_state_loss:"71000000" &

python ./main/run/full.py -- \
    env_name:"LunarLanderContinuous-v2" \
    train_coach:loss_function:"consistent_coach_loss"  \
    load:agent_path:"./subrepos/rl-trained-agents/sac/LunarLanderContinuous-v2_1/LunarLanderContinuous-v2.zip" \
    experiment_name:"find_best_coefficient_0.9" \
    train_coach:consistent_coach_loss:scale_future_state_loss:"91000000" &

python ./main/run/full.py -- \
    env_name:"LunarLanderContinuous-v2" \
    train_coach:loss_function:"consistent_coach_loss"  \
    load:agent_path:"./subrepos/rl-trained-agents/sac/LunarLanderContinuous-v2_1/LunarLanderContinuous-v2.zip" \
    experiment_name:"find_best_coefficient_1.1" \
    train_coach:consistent_coach_loss:scale_future_state_loss:"11000000" &

python ./main/run/full.py -- \
    env_name:"LunarLanderContinuous-v2" \
    train_coach:loss_function:"consistent_coach_loss"  \
    load:agent_path:"./subrepos/rl-trained-agents/sac/LunarLanderContinuous-v2_1/LunarLanderContinuous-v2.zip" \
    experiment_name:"find_best_coefficient_1.3" \
    train_coach:consistent_coach_loss:scale_future_state_loss:"31000000" &

python ./main/run/full.py -- \
    env_name:"LunarLanderContinuous-v2" \
    train_coach:loss_function:"consistent_coach_loss"  \
    load:agent_path:"./subrepos/rl-trained-agents/sac/LunarLanderContinuous-v2_1/LunarLanderContinuous-v2.zip" \
    experiment_name:"find_best_coefficient_1.5" \
    train_coach:consistent_coach_loss:scale_future_state_loss:"51000000" &

python ./main/run/full.py -- \
    env_name:"LunarLanderContinuous-v2" \
    train_coach:loss_function:"consistent_coach_loss"  \
    load:agent_path:"./subrepos/rl-trained-agents/sac/LunarLanderContinuous-v2_1/LunarLanderContinuous-v2.zip" \
    experiment_name:"find_best_coefficient_1.7" \
    train_coach:consistent_coach_loss:scale_future_state_loss:"71000000" &

python ./main/run/full.py -- \
    env_name:"LunarLanderContinuous-v2" \
    train_coach:loss_function:"consistent_coach_loss"  \
    load:agent_path:"./subrepos/rl-trained-agents/sac/LunarLanderContinuous-v2_1/LunarLanderContinuous-v2.zip" \
    experiment_name:"find_best_coefficient_1.9" \
    train_coach:consistent_coach_loss:scale_future_state_loss:"91000000" &

# HopperBulletEnv-v0
# AntBulletEnv-v0
# BipedalWalker-v3
# HalfCheetahBulletEnv-v0


 python ./main/run/full.py -- \
    env_name:"LunarLanderContinuous-v2" \
    train_coach:force_retrain:false train_coach:loss_function:"consistent_coach_loss" \
    load:agent_path:"./subrepos/rl-trained-agents/sac/LunarLanderContinuous-v2_1/LunarLanderContinuous-v2.zip" \
    experiment_name:"find_best_coefficient_10000000" \
    test_predictor:force_recompute:true \
    train_coach:consistent_coach_loss:scale_future_state_loss:"10000000"