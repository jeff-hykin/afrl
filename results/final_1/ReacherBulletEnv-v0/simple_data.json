{"override_save_path": false, "increment_factor": 1.2, "force_recompute": false, "graph_smoothing": 0, "number_of_episodes_for_baseline": 30, "number_of_epochs_for_optimal_parameters": 15, "number_of_episodes_for_testing": 10, "initial_epsilon": 3.5, "initial_horizon": 10, "reward_discount": 0.98, "acceptable_performance_levels": [0.8, 0.9, 0.95, 0.98, 0.99], "acceptable_performance_loss": 1, "acceptable_performance_level": 0.8, "confidence_interval_for_convergence": 90, "min_reward_single_timestep": 0, "max_reward_single_timestep": 100, "api": "v2", "agent": {"gamma": 0.98, "path": "./subrepos/rl-trained-agents/sac/ReacherBulletEnv-v0_1/ReacherBulletEnv-v0.zip"}, "coach": {"path": "models.ignore/coach/ReacherBulletEnv-v0/baseline_3"}, "plot": {"optimal_reward_points": [[0.8, 13.34709940752228], [0.9, 13.34709940752228], [0.95, 13.34709940752228], [0.98, 13.34709940752228], [0.99, 13.34709940752228]], "random_reward_points": [[0.8, 0], [0.9, 0], [0.95, 0], [0.98, 0], [0.99, 0]], "theory_reward_points": [[0.8, -108.75112125720112], [0.9, -108.75112125720112], [0.95, -108.75112125720112], [0.98, -108.75112125720112], [0.99, -108.75112125720112]], "ppac_reward_points": [[0.8, 7.369098240119894], [0.9, 5.271367033962556], [0.95, 7.842466165524086], [0.98, 8.183813557609211], [0.99, 7.958075775691636]], "n_step_horizon_reward_points": [[0.8, 6.527315155287309], [0.9, 3.003855400394877], [0.95, 10.939819554998257], [0.98, 4.566236253628714], [0.99, 1.9851402469142048]], "n_step_planlen_reward_points": [[0.8, 5.366077366458734], [0.9, 0.4546608595911636], [0.95, 11.075325160986402], [0.98, -0.17439973359152333], [0.99, 6.687485406530469]], "ppac_plan_length_points": [[0.8, 4.416], [0.9, 8.049333333333333], [0.95, 2.7479999999999998], [0.98, 6.335333333333334], [0.99, 4.484666666666667]], "n_step_horizon_plan_length_points": [[0.8, 6], [0.9, 10], [0.95, 4], [0.98, 8], [0.99, 6]], "n_step_planlen_plan_length_points": [[0.8, 6], [0.9, 10], [0.95, 4], [0.98, 8], [0.99, 6]]}, "0.8": {"optimal_epsilon": 0.8139881377648227, "optimal_horizon": 6}, "0.9": {"optimal_epsilon": 0.8139881377648227, "optimal_horizon": 10}, "0.95": {"optimal_epsilon": 0.8139881377648227, "optimal_horizon": 4}, "0.98": {"optimal_epsilon": 0.8139881377648227, "optimal_horizon": 8}, "0.99": {"optimal_epsilon": 0.8139881377648227, "optimal_horizon": 6}}