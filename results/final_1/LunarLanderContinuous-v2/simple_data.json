{"override_save_path": false, "increment_factor": 1.2, "force_recompute": false, "graph_smoothing": 0, "number_of_episodes_for_baseline": 30, "number_of_epochs_for_optimal_parameters": 15, "number_of_episodes_for_testing": 10, "initial_epsilon": 3.5, "initial_horizon": 10, "reward_discount": 0.98, "acceptable_performance_levels": [0.8, 0.9, 0.95, 0.98, 0.99], "acceptable_performance_loss": 1, "acceptable_performance_level": 0.8, "confidence_interval_for_convergence": 90, "min_reward_single_timestep": -100, "max_reward_single_timestep": 70, "horizons": {"0.0": 1, "0.005": 10, "0.01": 20}, "api": "v2", "agent": {"gamma": 0.99, "path": "./subrepos/rl-trained-agents/sac/LunarLanderContinuous-v2_1/LunarLanderContinuous-v2.zip"}, "coach": {"path": "models.ignore/coach/LunarLanderContinuous-v2/baseline_3"}, "plot": {"optimal_reward_points": [[0.5, 24.379314870747702], [0.8, 24.379314870747702], [0.9, 24.379314870747702], [0.95, 24.379314870747702], [0.97, 24.379314870747702], [0.99, 24.379314870747702], [1.0, 24.379314870747702]], "random_reward_points": [[0.5, 0], [0.8, 0], [0.9, 0], [0.95, 0], [0.97, 0], [0.99, 0], [1.0, 0]], "theory_reward_points": [[0.5, -605.5396666107338], [0.8, -406.03156475888204], [0.9, -378.8378490524348], [0.95, -1382.1921871868658], [0.97, -789.6088228940749], [0.99, -188.07158908587104], [1.0, -246.38569927534292]], "ppac_reward_points": [[0.5, 28.948328181229577], [0.8, 20.66664503560112], [0.9, 28.249504101477754], [0.95, 21.904028862618887], [0.97, 16.930093429214363], [0.99, 32.2303206499341], [1.0, 26.633202802722025]], "n_step_horizon_reward_points": [[0.5, 27.461400099553934], [0.8, 21.256081794197822], [0.9, 20.783247195369192], [0.95, 20.79687998731237], [0.97, 16.049376185530743], [0.99, 20.4939523365127], [1.0, 25.924417129334515]], "n_step_planlen_reward_points": [[0.5, 24.41777611782325], [0.8, 20.777720074835482], [0.9, 19.921971805415833], [0.95, 23.31416440575436], [0.97, 24.636751438444975], [0.99, 30.191432678060114], [1.0, 23.308503952333922]], "ppac_plan_length_points": [[0.5, 2.8257065493811484], [0.8, 2.676012244310826], [0.9, 4.113691270343223], [0.95, 5.295717414527351], [0.97, 3.7270194538048944], [0.99, 3.938438581751248], [1.0, 4.173539070891206]], "n_step_horizon_plan_length_points": [[0.5, 4], [0.8, 4], [0.9, 6], [0.95, 8], [0.97, 6], [0.99, 6], [1.0, 6]], "n_step_planlen_plan_length_points": [[0.5, 4], [0.8, 4], [0.9, 6], [0.95, 8], [0.97, 6], [0.99, 6], [1.0, 6]]}, "0.8": {"optimal_epsilon": 1.4065715020576135, "optimal_horizon": 4}, "0.9": {"optimal_epsilon": 1.1721429183813445, "optimal_horizon": 6}, "0.95": {"optimal_epsilon": 1.4065715020576135, "optimal_horizon": 8}, "0.98": {"optimal_epsilon": 0.8139881377648227, "optimal_horizon": 6}, "0.99": {"optimal_epsilon": 0.8139881377648227, "optimal_horizon": 6}, "0.5": {"optimal_epsilon": 2.0254629629629632, "optimal_horizon": 4}, "0.97": {"optimal_epsilon": 0.8139881377648227, "optimal_horizon": 6}, "1.0": {"optimal_epsilon": 1.1721429183813445, "optimal_horizon": 6}}