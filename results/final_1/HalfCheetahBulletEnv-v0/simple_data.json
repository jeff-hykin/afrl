{"override_save_path": false, "increment_factor": 1.2, "force_recompute": false, "graph_smoothing": 0, "number_of_episodes_for_baseline": 30, "number_of_epochs_for_optimal_parameters": 15, "number_of_episodes_for_testing": 10, "initial_epsilon": 3.5, "initial_horizon": 10, "reward_discount": 0.98, "acceptable_performance_levels": [0.8, 0.9, 0.95, 0.98, 0.99], "acceptable_performance_loss": 1, "acceptable_performance_level": 0.8, "confidence_interval_for_convergence": 90, "min_reward_single_timestep": -60, "max_reward_single_timestep": 100, "horizons": {"0": 1, "0.001": 11, "0.01": 13, "0.1": 26}, "api": "v2", "agent": {"gamma": 0.98, "path": "subrepos/rl-trained-agents/sac/HalfCheetahBulletEnv-v0_1/HalfCheetahBulletEnv-v0.zip"}, "coach": {"path": "models.ignore/coach/HalfCheetahBulletEnv-v0/baseline_3"}, "plot": {"optimal_reward_points": [[0.8, 104.72384016144102], [0.9, 104.72384016144102], [0.95, 104.72384016144102], [0.98, 104.72384016144102], [0.99, 104.72384016144102]], "random_reward_points": [[0.8, 0], [0.9, 0], [0.95, 0], [0.98, 0], [0.99, 0]], "theory_reward_points": [[0.8, -1067.4190782199034], [0.9, -709.2642976033817], [0.95, -709.2642976033817], [0.98, -709.2642976033817], [0.99, -709.2642976033817]], "ppac_reward_points": [[0.8, 65.4186599795275], [0.9, 90.90415040823873], [0.95, 86.63630950097601], [0.98, 85.66165650054245], [0.99, 82.58599226127801]], "n_step_horizon_reward_points": [[0.8, 47.05080604517784], [0.9, 21.06450643894461], [0.95, 35.420951429454064], [0.98, 32.97369293279781], [0.99, 38.919540629374495]], "n_step_planlen_reward_points": [[0.8, 92.1697821952913], [0.9, 48.96191945477563], [0.95, 57.578924389977246], [0.98, 48.973818477932284], [0.99, 56.55948655164076]], "ppac_plan_length_points": [[0.8, 1.552], [0.9, 3.3029], [0.95, 3.2420999999999998], [0.98, 3.0977], [0.99, 3.2717]], "n_step_horizon_plan_length_points": [[0.8, 4], [0.9, 6], [0.95, 6], [0.98, 6], [0.99, 6]], "n_step_planlen_plan_length_points": [[0.8, 4], [0.9, 6], [0.95, 6], [0.98, 6], [0.99, 6]]}, "0.8": {"optimal_epsilon": 1.1721429183813445, "optimal_horizon": 4}, "0.9": {"optimal_epsilon": 0.8139881377648227, "optimal_horizon": 6}, "0.95": {"optimal_epsilon": 0.8139881377648227, "optimal_horizon": 6}, "0.98": {"optimal_epsilon": 0.8139881377648227, "optimal_horizon": 6}, "0.99": {"optimal_epsilon": 0.8139881377648227, "optimal_horizon": 6}}