{"override_save_path": false, "increment_factor": 1.2, "force_recompute": false, "graph_smoothing": 0, "number_of_episodes_for_baseline": 30, "number_of_epochs_for_optimal_parameters": 15, "number_of_episodes_for_testing": 10, "initial_epsilon": 3.5, "initial_horizon": 10, "reward_discount": 0.98, "acceptable_performance_levels": [0.8, 0.9, 0.95, 0.98, 0.99], "acceptable_performance_loss": 1, "acceptable_performance_level": 0.8, "confidence_interval_for_convergence": 90, "min_reward_single_timestep": 19, "max_reward_single_timestep": 105, "horizons": {"0": 1, "0.0007": 4, "0.0015": 16, "0.002": 26}, "api": "v2", "agent": {"gamma": 0.98, "path": "subrepos/rl-trained-agents/sac/AntBulletEnv-v0_1/AntBulletEnv-v0.zip"}, "coach": {"path": "models.ignore/coach/AntBulletEnv-v0/baseline_3"}, "plot": {"optimal_reward_points": [[0.5, 101.899812911828], [0.8, 101.899812911828], [0.9, 101.899812911828], [0.95, 101.899812911828], [0.97, 101.899812911828], [0.99, 101.899812911828], [1.0, 101.899812911828]], "random_reward_points": [[0.5, 0], [0.8, 0], [0.9, 0], [0.95, 0], [0.97, 0], [0.99, 0], [1.0, 0]], "theory_reward_points": [[0.5, -2814.766853754839], [0.8, -1070.2431054695166], [0.9, -712.0883248529947], [0.95, -712.0883248529947], [0.97, -712.0883248529947], [0.99, -712.0883248529947], [1.0, -712.0883248529947]], "ppac_reward_points": [[0.5, 52.873439788526376], [0.8, 72.35515954842134], [0.9, 88.9822630649859], [0.95, 86.86684079616681], [0.97, 87.04406031977014], [0.99, 86.3669478400225], [1.0, 87.15370533972754]], "n_step_horizon_reward_points": [[0.5, 99.73117009459584], [0.8, 75.22853627256072], [0.9, 68.28541432269215], [0.95, 70.19641021236829], [0.97, 78.46192938067088], [0.99, 67.65967612376676], [1.0, 81.3697579242409]], "n_step_planlen_reward_points": [[0.5, 102.25251490807993], [0.8, 99.91724032694907], [0.9, 73.85587708432799], [0.95, 84.70549806893891], [0.97, 81.19746978212835], [0.99, 81.8675080841697], [1.0, 77.80363336600412]], "ppac_plan_length_points": [[0.5, 0.8499], [0.8, 1.8758000000000001], [0.9, 2.1039], [0.95, 2.0631], [0.97, 2.0878], [0.99, 3.393], [1.0, 2.029]], "n_step_horizon_plan_length_points": [[0.5, 2], [0.8, 4], [0.9, 4], [0.95, 4], [0.97, 4], [0.99, 6], [1.0, 4]], "n_step_planlen_plan_length_points": [[0.5, 2], [0.8, 4], [0.9, 4], [0.95, 4], [0.97, 4], [0.99, 6], [1.0, 4]]}, "0.8": {"optimal_epsilon": 1.1721429183813445, "optimal_horizon": 4}, "0.9": {"optimal_epsilon": 0.8139881377648227, "optimal_horizon": 4}, "0.95": {"optimal_epsilon": 0.8139881377648227, "optimal_horizon": 4}, "0.98": {"optimal_epsilon": 0.8139881377648227, "optimal_horizon": 4}, "0.5": {"optimal_epsilon": 2.916666666666667, "optimal_horizon": 2}, "0.97": {"optimal_epsilon": 0.8139881377648227, "optimal_horizon": 4}, "0.99": {"optimal_epsilon": 0.8139881377648227, "optimal_horizon": 6}, "1.0": {"optimal_epsilon": 0.8139881377648227, "optimal_horizon": 4}}