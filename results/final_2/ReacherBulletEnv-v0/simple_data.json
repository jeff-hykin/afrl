{"override_save_path": false, "increment_factor": 1.2, "force_recompute": true, "graph_smoothing": 0, "number_of_episodes_for_baseline": 30, "number_of_epochs_for_optimal_parameters": 50, "number_of_episodes_for_testing": 50, "initial_epsilon": 3.5, "initial_horizon": 10, "reward_discount": 0.98, "acceptable_performance_levels": [0.5, 0.8, 0.9, 0.95, 0.97, 0.99, 1.0], "acceptable_performance_loss": 1, "acceptable_performance_level": 0.8, "confidence_interval_for_convergence": 90, "min_reward_single_timestep": 0, "max_reward_single_timestep": 100, "api": "v2", "agent": {"gamma": 0.98, "path": "./subrepos/rl-trained-agents/sac/ReacherBulletEnv-v0_1/ReacherBulletEnv-v0.zip"}, "coach": {"path": "models.ignore/coach/ReacherBulletEnv-v0/baseline_3"}, "0.5": {"optimal_epsilon": 0.8139881377648227, "optimal_horizon": 10}, "plot": {"optimal_reward_points": [[0.5, 14.376247289535533], [0.8, 14.376247289535533], [0.9, 14.376247289535533], [0.95, 14.376247289535533], [0.97, 14.376247289535533], [0.99, 14.376247289535533], [1.0, 14.376247289535533]], "random_reward_points": [[0.5, 0], [0.8, 0], [0.9, 0], [0.95, 0], [0.97, 0], [0.99, 0], [1.0, 0]], "theory_reward_points": [[0.5, -107.72197337518787], [0.8, -26.5141997673554], [0.9, -11.653551184179763], [0.95, 2.964473968777913], [0.97, -3.7000016505445377], [0.99, 4.866436188904181], [1.0, 3.915455078841047]], "ppac_reward_points": [[0.5, 7.518941922977239], [0.8, 11.40615810586073], [0.9, 14.306974449334376], [0.95, 14.67124387727597], [0.97, 13.363635281082537], [0.99, 12.459051389512057], [1.0, 13.156557446943431]], "n_step_horizon_reward_points": [[0.5, 4.11301559962705], [0.8, 6.524009548773992], [0.9, -0.8224485991424423], [0.95, 7.122714723114927], [0.97, 0.6013266520822536], [0.99, 7.3171145408345595], [1.0, -0.5908570133782656]], "n_step_planlen_reward_points": [[0.5, 4.296016820255289], [0.8, 6.784635381836276], [0.9, 2.6744462303795244], [0.95, 12.271686021764266], [0.97, 1.2526577870434459], [0.99, 13.814914174253019], [1.0, 2.269797948027625]], "ppac_plan_length_points": [[0.5, 8.1936], [0.8, 4.134933333333334], [0.9, 11.8924], [0.95, 1.7336], [0.97, 10.849333333333334], [0.99, 1.69], [1.0, 8.360933333333334]], "n_step_horizon_plan_length_points": [[0.5, 10], [0.8, 6], [0.9, 20], [0.95, 4], [0.97, 20], [0.99, 4], [1.0, 20]], "n_step_planlen_plan_length_points": [[0.5, 10], [0.8, 6], [0.9, 20], [0.95, 4], [0.97, 20], [0.99, 4], [1.0, 20]]}, "0.8": {"optimal_epsilon": 0.2726029803792729, "optimal_horizon": 6}, "0.9": {"optimal_epsilon": 0.17353198982476864, "optimal_horizon": 20}, "0.95": {"optimal_epsilon": 0.0760784888050508, "optimal_horizon": 4}, "0.97": {"optimal_epsilon": 0.12050832626720047, "optimal_horizon": 20}, "0.99": {"optimal_epsilon": 0.06339874067087567, "optimal_horizon": 4}, "1.0": {"optimal_epsilon": 0.06973861473796324, "optimal_horizon": 20}}