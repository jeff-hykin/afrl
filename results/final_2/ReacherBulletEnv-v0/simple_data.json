{"override_save_path": false, "increment_factor": 1.2, "force_recompute": false, "graph_smoothing": 0, "number_of_episodes_for_baseline": 30, "number_of_epochs_for_optimal_parameters": 15, "number_of_episodes_for_testing": 10, "initial_epsilon": 3.5, "initial_horizon": 10, "reward_discount": 0.98, "acceptable_performance_levels": [0.8, 0.9, 0.95, 0.98, 0.99], "acceptable_performance_loss": 1, "acceptable_performance_level": 0.8, "confidence_interval_for_convergence": 90, "min_reward_single_timestep": 0, "max_reward_single_timestep": 100, "api": "v2", "agent": {"gamma": 0.98, "path": "./subrepos/rl-trained-agents/sac/ReacherBulletEnv-v0_1/ReacherBulletEnv-v0.zip"}, "coach": {"path": "models.ignore/coach/ReacherBulletEnv-v0/baseline_3"}, "plot": {"optimal_reward_points": [[0.5, 15.137909031815832], [0.8, 15.137909031815832], [0.9, 15.137909031815832], [0.95, 15.137909031815832], [0.97, 15.137909031815832], [0.99, 15.137909031815832], [1.0, 15.137909031815832]], "random_reward_points": [[0.5, 0], [0.8, 0], [0.9, 0], [0.95, 0], [0.97, 0], [0.99, 0], [1.0, 0]], "theory_reward_points": [[0.5, -131.37995576585223], [0.8, -106.96031163290756], [0.9, -106.96031163290756], [0.95, -106.96031163290756], [0.97, -106.96031163290756], [0.99, -106.96031163290756], [1.0, -106.96031163290756]], "ppac_reward_points": [[0.5, 6.689261236205484], [0.8, 8.749000594592792], [0.9, 6.542414617144085], [0.95, 11.847629600077642], [0.97, 9.254504945654217], [0.99, 5.88785369259508], [1.0, 3.581276476618014]], "n_step_horizon_reward_points": [[0.5, 7.873182779926288], [0.8, 1.8417150933502904], [0.9, 2.9646047937701625], [0.95, 2.142051359269452], [0.97, 7.186647467593574], [0.99, 1.9430875035018116], [1.0, 9.09480358884532]], "n_step_planlen_reward_points": [[0.5, 2.5966283024392016], [0.8, 4.297129256567319], [0.9, -1.415450235319778], [0.95, 1.14352941244585], [0.97, -3.9806597105643644], [0.99, 3.8693948475734508], [1.0, 6.91839868756998]], "ppac_plan_length_points": [[0.5, 6.386666666666667], [0.8, 4.503333333333333], [0.9, 9.724666666666668], [0.95, 9.918666666666667], [0.97, 6.216], [0.99, 8.952666666666667], [1.0, 4.506666666666667]], "n_step_horizon_plan_length_points": [[0.5, 8], [0.8, 6], [0.9, 12], [0.95, 12], [0.97, 8], [0.99, 11], [1.0, 6]], "n_step_planlen_plan_length_points": [[0.5, 8], [0.8, 6], [0.9, 12], [0.95, 12], [0.97, 8], [0.99, 11], [1.0, 6]]}, "0.8": {"optimal_epsilon": 0.8139881377648227, "optimal_horizon": 6}, "0.9": {"optimal_epsilon": 0.8139881377648227, "optimal_horizon": 12}, "0.95": {"optimal_epsilon": 0.8139881377648227, "optimal_horizon": 12}, "0.98": {"optimal_epsilon": 0.8139881377648227, "optimal_horizon": 4}, "0.99": {"optimal_epsilon": 0.8139881377648227, "optimal_horizon": 11}, "0.5": {"optimal_epsilon": 0.9767857653177872, "optimal_horizon": 8}, "0.97": {"optimal_epsilon": 0.8139881377648227, "optimal_horizon": 8}, "1.0": {"optimal_epsilon": 0.8139881377648227, "optimal_horizon": 6}}