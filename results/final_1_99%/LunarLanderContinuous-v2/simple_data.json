{"force_recompute": true, "graph_smoothing": 0, "number_of_episodes_for_baseline": 30, "number_of_epochs_for_optimal_parameters": 15, "number_of_episodes_for_testing": 10, "initial_epsilon": 10.1, "initial_horizon": 16, "reward_discount": 0.98, "acceptable_performance_loss": 1, "acceptable_performance_level": 0.8, "confidence_interval_for_convergence": 90, "min_reward_single_timestep": -100, "max_reward_single_timestep": 70, "horizons": {"0.0": 1, "0.005": 10, "0.01": 20}, "api": "v2", "agent": {"gamma": 0.99, "path": "./subrepos/rl-trained-agents/sac/LunarLanderContinuous-v2_1/LunarLanderContinuous-v2.zip"}, "coach": {"path": "models.ignore/coach/LunarLanderContinuous-v2/final_1_99%/"}, "optimal_epsilon": 1.9950617283950616, "optimal_horizon": 8}