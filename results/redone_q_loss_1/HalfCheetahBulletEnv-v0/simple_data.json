{"force_recompute": false, "graph_smoothing": 0, "number_of_episodes_for_baseline": 30, "number_of_epochs_for_optimal_parameters": 15, "number_of_episodes_for_testing": 10, "initial_epsilon": 0.7, "initial_horizon": 42, "reward_discount": 0.98, "acceptable_performance_loss": 2, "confidence_interval_for_convergence": 90, "min_reward_single_timestep": -60, "max_reward_single_timestep": 100, "horizons": {"0": 1, "0.001": 11, "0.01": 13, "0.1": 26}, "api": "v2", "agent": {"gamma": 0.98, "path": "subrepos/rl-trained-agents/sac/HalfCheetahBulletEnv-v0_1/HalfCheetahBulletEnv-v0.zip"}, "coach": {"path": "models.ignore/coach/HalfCheetahBulletEnv-v0/redone_q_loss_1/"}, "optimal_epsilon": 0.09218106995884773, "optimal_horizon": 4}