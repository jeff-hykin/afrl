# NOTE: names in parentheses are special
# all other names are not special
(project):
    # paths the code will probably need to use
    (path_to):
        folder:
            agent_models: "./data/models/agents/"
            dynamics_models: "./data/models/dynamics/"
            results: "./data/results"
        file:
            humanoid_agent_model: "./log/best_model.zip"
    
    # this is your local-machine config choices
    # (should point to a file that is git-ignored)
    # (this file will be auto-generated with the correct format)
    (configuration): ./configuration.ignore.yaml
    
    # below are options that the config file can choose
    #     when multiple options are selected
    #     their keys/values will be merged recursively
    (configuration_options):
        (default):
            mode: development
            has_gpu: true
            default_env_names: ["LunarLanderContinuous-v2", "MountainCarContinuous-v0"] # 'AntBulletEnv-v0', 'LunarLanderContinuous-v2', BipedalWalker-v3, 'HalfCheetahBulletEnv-v0'
            train_agent:
                iterations: 100000
            train_dynamics:
                number_of_episodes: 20
                number_of_epochs: 100
                train_test_split: 0.7
                minibatch_size: 32
            train_afrl:
                number_of_experiments: 50
                env_settings:
                    LunarLanderContinuous-v2:
                        max_score: 70  # discounted ep reward
                        min_score: -100
                        horizons: # maps "epsilon coefficients" to horizons
                            0.001: 5
                            0.0025: 5
                            0.005: 10
                            0.0075: 15
                            0.01: 20
        
        GPU=NONE:
            has_gpu: false
        